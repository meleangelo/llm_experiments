{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f21b323-4a0b-4b52-9f60-9c3def8f7c86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                             CHATBOT GINA - ITALIAN GRANDMA                  #\n",
    "###############################################################################\n",
    "# most of the structure for the chatbot was taken from Mauro Di Pietro blogs and\n",
    "# https://github.com/mdipietro09/GenerativeAI/blob/main/Chatbot/chatbot.py\n",
    "\n",
    "# Setup\n",
    "## module for speech-to-text\n",
    "import speech_recognition as sr \n",
    "\n",
    "## module for text-to-speech\n",
    "from gtts import gTTS \n",
    "\n",
    "## use ollama for LLMs\n",
    "import ollama \n",
    "\n",
    "## change the model below if needed. (need to pull it in ollama)\n",
    "model = \"qwen2.5\"\n",
    "\n",
    "## describe the personality of the chatbot and \n",
    "## instructions on how to answer. \n",
    "## This will be sent to the LLM as system prompt\n",
    "\n",
    "system_prompt = f'''Your name is Grandma Gina. \n",
    "You are an italian grandma, sarcastic to the point of being cynical. \n",
    "You always make fun of everyone when answering the questions. \n",
    "If someone needs a cheer up, you offer to prepare some traditional italian dish, like lasagna or carbonara. \n",
    "When you refer to yourself you always use the third person. \n",
    "Your responses always include only two sentences.'''\n",
    "\n",
    "## for data\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Build the ChatBot\n",
    "class ChatBot():\n",
    "    def __init__(self, name):\n",
    "        print(\"--- starting up\", name, \"---\")\n",
    "        self.name = name.lower()\n",
    "        self.text = \"\"\n",
    "\n",
    "    def speech_to_text(self):\n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.Microphone() as mic:\n",
    "            recognizer.adjust_for_ambient_noise(mic, duration=1)\n",
    "            print(\"listening...\")\n",
    "            audio = recognizer.listen(mic)\n",
    "        try:\n",
    "            self.text = recognizer.recognize_google(audio)\n",
    "            print(\"me --> \", self.text)\n",
    "        except:\n",
    "            print(\"me -->  ERROR\")\n",
    "\n",
    "    @staticmethod\n",
    "    def text_to_speech(text):\n",
    "        print(\"ai --> \", text)\n",
    "        speaker = gTTS(text=text, lang=\"en\", slow=False)\n",
    "        speaker.save(\"res.mp3\")\n",
    "        os.system(\"afplay res.mp3\")  #mac->afplay | windows->start\n",
    "        os.remove(\"res.mp3\")\n",
    "\n",
    "    ## predetermined commands\n",
    "    def wake_up(self, text):\n",
    "        lst = [\"wake up \"+self.name, self.name+\"wake up \", \"hey \"+self.name]\n",
    "        return True if any(i in ai.text.lower() for i in lst) else False\n",
    "\n",
    "    def what(self, text):\n",
    "        lst = [\"what are you\", \"who are you\"]\n",
    "        return True if any(i in ai.text.lower() for i in lst) else False\n",
    "\n",
    "    \n",
    "\n",
    "# Run the AI\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    ai = ChatBot(name=\"Grandma Gina\")\n",
    "    #ai.text = \"\"\n",
    "    \n",
    "    while True:\n",
    "        ai.speech_to_text()\n",
    "\n",
    "        ## wake up\n",
    "        if ai.wake_up(ai.text) is True:\n",
    "            res = \"Hello I am Grandma Gina, how are you doing?\"\n",
    "\n",
    "        ## what\n",
    "        elif ai.what(ai.text) is True:\n",
    "            res = \"I am an AI created by Angelo.\"\n",
    "\n",
    "        \n",
    "        ## respond politely\n",
    "        elif any(i in ai.text for i in [\"thank\",\"thanks\"]):\n",
    "            res = np.random.choice([\"you're welcome!\",\"no problema!\",\"Grandma Gina is here if you need her!\"])\n",
    "        \n",
    "        ## general conversation\n",
    "        else:   \n",
    "            \n",
    "            prompt = [{\"role\":\"system\", \"content\":system_prompt}]\n",
    "            prompt = prompt.append( {\"role\":\"user\", \"content\":ai.text} ) \n",
    "           \n",
    "            res = ollama.generate(model=model, prompt=system_prompt + ai.text)[\"response\"]\n",
    "            res = res.split(\"\\n\")[0]\n",
    "\n",
    "        ai.text_to_speech(res)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f36bcb-948e-4984-8159-6f97315665c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d031035-96ac-4b2d-8c28-169a6d108498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
